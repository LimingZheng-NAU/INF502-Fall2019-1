Title: Dropout: A Simple Way to Prevent Neural Networks from Overfitting
Venue: Journal of Machine Learning Research
Pages: 30
Outcomes:
- Proposes a method called Dropout to avoid overfitting
- The method is computationally efficient than other methods such as merging different architectures or using large architecture,.
- It improves the efficiency of the model

Link: https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf
